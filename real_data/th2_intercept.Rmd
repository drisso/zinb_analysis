---
title: "Role of intercept in Th2 data"
author: "Davide Risso"
date: "10/11/2016"
output: 
  html_document: 
    fig_height: 10
    fig_width: 10
    toc: yes
    code_folding: hide
    toc_float: yes
---

```{r options, echo=FALSE, results="hide",mesasge=FALSE, error=FALSE, include=FALSE, autodep=TRUE}
knitr::opts_chunk$set(fig.align="center", cache=TRUE, error=FALSE, message=FALSE, warning=TRUE)
library(SummarizedExperiment)
library(scRNAseq)
library(zinb)
library(scran)
library(EDASeq)
library(ggplot2)
library(magrittr)
library(matrixStats)

library(RColorBrewer)
cols <- brewer.pal(8, "Set1")
cols2 <- c(brewer.pal(8, "Set2"), brewer.pal(8, "Set3"), brewer.pal(8, "Set1"))

set.seed(2535)
```

## TL;DR

Here, we explore the TH2 dataset, to try and understand if it's only the Fluidigm data that is somewhat off. 

The tricky part of this analysis is that we don't know the ground truth for this dataset, so it's not easy to understand which representaion is better. However, we do not see the issues with W seen in the Fluidigm data, suggesting that that is a problem specific to that dataset.

## Data

As a first pass, I will only focus on the cells that passed the QC filters (by the original authors) and that were not doublets.

Select cells, remove ERCC spike-ins, filter out the genes that do not have at least 10 counts in at least 10 cells.

```{r datain}
data("th2")
th2_core <- th2[grep("^ERCC-", rownames(th2), invert = TRUE),
                    which(colData(th2)$single=="OK" & colData(th2)$Buettner_filter=="PASS")]

filter <- apply(assay(th2_core)>10, 1, sum)>=10
```

Number of retained genes:
```{r}
print(sum(filter))
```

To speed up the computations, I will focus on the top 1,000 most variable genes.

```{r filtering}
th2_core <- th2_core[filter,]
core <- assay(th2_core)

vars <- rowVars(log1p(core))
names(vars) <- rownames(core)
vars <- sort(vars, decreasing = TRUE)
core <- core[names(vars)[1:1000],]
```

First, let's look at PCA (of the log counts) for reference.

```{r pca}
detection_rate <- colSums(core>0)
coverage <- colSums(core)
gata3 <- log2(assay(th2_core)["Gata3",])

pca <- prcomp(t(log1p(core)))
data.frame(pca$x) %>% ggplot(aes(PC1, PC2)) + geom_point(aes(color=gata3), size=3) + scale_colour_gradient(low="blue", high="green") + theme_classic()
```

```{r pca_cor}
df <- data.frame(PC1=pca$x[,1], PC2=pca$x[,2], detection_rate=detection_rate, coverage=coverage)
pairs(df, pch=19)

print(cor(df, method="spearman"))
```

## V intercept in both Mu and Pi

```{r zinb}
print(system.time(zinb_Vall <- zinbFit(core, ncores = 3, K = 2)))
```

Plot the results with cells colored according to Gata3, mimicking the figure from the original paper.

```{r zinb_plot}
data.frame(W1=zinb_Vall@W[,1], W2=zinb_Vall@W[,2]) %>% ggplot(aes(W1, W2)) + geom_point(aes(color=gata3), size=3) + scale_colour_gradient(low="blue", high="green") + theme_classic()
```

### Explore Gamma estimates

One interpretation of the model is that $\gamma_mu$ will act as a "size factor". Here, we check whether it captures sequencing depth and/or detection rate.

```{r gamma}
#total number of detected genes in the cell
df <- data.frame(W1=zinb_Vall@W[,1], W2=zinb_Vall@W[,2], gamma_mu = zinb_Vall@gamma_mu[1,], gamma_pi = zinb_Vall@gamma_pi[1,], detection_rate=detection_rate, coverage=coverage)
pairs(df, pch=19)

print(cor(df, method="spearman"))
```

$\gamma_pi$ clearly captures the detection rate and $\gamma_mu$ clearly captures the coverage.
Interestingly, the two estimates are positively correlated.

```{r mu_pi}
par(mfrow=c(1, 2))
plot(rowMeans(getPi(zinb_Vall)), detection_rate, xlab="Average estimated Pi", ylab="detection rate", pch=19)

plot(rowMeans(log1p(getMu(zinb_Vall))), coverage, xlab="Average estimated log Mu", ylab="coverage", pch=19)
```

It is worth looking at the other estimates as well, namely, $\beta$ and $\alpha$.

```{r other_pars}
par(mfrow=c(2, 2))
boxplot(zinb_Vall@beta_mu[1,], main="Beta_Mu")
boxplot(zinb_Vall@beta_pi[1,], main="Beta_Pi")

plot(t(zinb_Vall@alpha_mu), xlab="Alpha_Mu 1", ylab="Alpha_Mu 2", main="Alpha_Mu")
plot(t(zinb_Vall@alpha_pi), xlab="Alpha_Pi 1", ylab="Alpha_Pi 2", main="Alpha_Pi")
```

## No V intercept

```{r no_int}
print(system.time(zinb_Vnone <- zinbFit(core, ncores = 3, K = 2, V=matrix(0, ncol=1, nrow=NROW(core)))))
```

```{r no_int_plot}
data.frame(W1=zinb_Vnone@W[,1], W2=zinb_Vnone@W[,2]) %>% ggplot(aes(W1, W2)) + geom_point(aes(color=gata3), size=3) + scale_colour_gradient(low="blue", high="green") + theme_classic()
```

```{r no_int_w}
df <- data.frame(W1 = zinb_Vnone@W[,1], W2 = zinb_Vnone@W[,2], detection_rate=detection_rate, coverage=coverage)
pairs(df, pch=19)

print(cor(df, method="spearman"))
```

```{r no_int_mu_pi}
par(mfrow=c(1, 2))
plot(rowMeans(getPi(zinb_Vnone)), detection_rate, xlab="Average estimated Pi", ylab="detection rate", pch=19)

plot(rowMeans(log1p(getMu(zinb_Vnone))), coverage, xlab="Average estimated log Mu", ylab="coverage", pch=19)
```

It is worth looking at the other estimates as well, namely, $\beta$ and $\alpha$.

```{r no_int_pars}
par(mfrow=c(2, 2))
boxplot(zinb_Vnone@beta_mu[1,], main="Beta_Mu")
boxplot(zinb_Vnone@beta_pi[1,], main="Beta_Pi")

plot(t(zinb_Vnone@alpha_mu), xlab="Alpha_Mu 1", ylab="Alpha_Mu 2", main="Alpha_Mu")
plot(t(zinb_Vnone@alpha_pi), xlab="Alpha_Pi 1", ylab="Alpha_Pi 2", main="Alpha_Pi")
```

## V intercept only in Mu

```{r v_mu}
V <- cbind(rep(0, NROW(core)), rep(1, NROW(core)))

print(system.time(zinb_Vmu <- zinbFit(core, ncores = 3, K = 2, V=V, which_V_mu=2L, which_V_pi=1L)))
```

```{r v_mu_plot}
data.frame(W1=zinb_Vmu@W[,1], W2=zinb_Vmu@W[,2]) %>% ggplot(aes(W1, W2)) + geom_point(aes(color=gata3), size=3) + scale_colour_gradient(low="blue", high="green") + theme_classic()
```

```{r v_mu_w}
df <- data.frame(W1 = zinb_Vmu@W[,1], W2 = zinb_Vmu@W[,2], gamma_mu = zinb_Vmu@gamma_mu[1,], detection_rate=detection_rate, coverage=coverage)
pairs(df, pch=19)

print(cor(df, method="spearman"))
```

```{r v_mu_pi}
par(mfrow=c(1, 2))
plot(rowMeans(getPi(zinb_Vmu)), detection_rate, xlab="Average estimated Pi", ylab="detection rate", pch=19)

plot(rowMeans(log1p(getMu(zinb_Vmu))), coverage, xlab="Average estimated log Mu", ylab="coverage", pch=19)
```

It is worth looking at the other estimates as well, namely, $\beta$ and $\alpha$.

```{r v_mu_pars}
par(mfrow=c(2, 2))
boxplot(zinb_Vmu@beta_mu[1,], main="Beta_Mu")
boxplot(zinb_Vmu@beta_pi[1,], main="Beta_Pi")

plot(t(zinb_Vmu@alpha_mu), xlab="Alpha_Mu 1", ylab="Alpha_Mu 2", main="Alpha_Mu")
plot(t(zinb_Vmu@alpha_pi), xlab="Alpha_Pi 1", ylab="Alpha_Pi 2", main="Alpha_Pi")
```

## V intercept only in Pi

```{r v_pi}
print(system.time(zinb_Vpi <- zinbFit(core, ncores = 3, K = 2, V=V, which_V_mu=1L, which_V_pi=2L)))
```

```{r v_pi_plot}
data.frame(W1=zinb_Vpi@W[,1], W2=zinb_Vpi@W[,2]) %>% ggplot(aes(W1, W2)) + geom_point(aes(color=gata3), size=3) + scale_colour_gradient(low="blue", high="green") + theme_classic()
```

```{r v_pi_w}
df <- data.frame(W1 = zinb_Vpi@W[,1], W2 = zinb_Vpi@W[,2], gamma_pi = zinb_Vpi@gamma_pi[1,], detection_rate=detection_rate, coverage=coverage)
pairs(df, pch=19)

print(cor(df, method="spearman"))
```

```{r v_pi_pi}
par(mfrow=c(1, 2))
plot(rowMeans(getPi(zinb_Vpi)), detection_rate, xlab="Average estimated Pi", ylab="detection rate", pch=19)

plot(rowMeans(log1p(getMu(zinb_Vpi))), coverage, xlab="Average estimated log Mu", ylab="coverage", pch=19)
```

It is worth looking at the other estimates as well, namely, $\beta$ and $\alpha$.

```{r v_pi_pars}
par(mfrow=c(2, 2))
boxplot(zinb_Vpi@beta_mu[1,], main="Beta_Mu")
boxplot(zinb_Vpi@beta_pi[1,], main="Beta_Pi")

plot(t(zinb_Vpi@alpha_mu), xlab="Alpha_Mu 1", ylab="Alpha_Mu 2", main="Alpha_Mu")
plot(t(zinb_Vpi@alpha_pi), xlab="Alpha_Pi 1", ylab="Alpha_Pi 2", main="Alpha_Pi")
```

```{r write_csv}
## write matrices to file to feed to ZIFA in python
write.csv(log1p(core), file="logcounts_th2.csv")
```

## Using all genes

```{r zinb_all}
core <- assay(th2_core)
dim(core)
print(system.time(zinb_all <- zinbFit(core, ncores = 3, K = 2)))
```

```{r zinb_all_plot}
data.frame(W1=zinb_all@W[,1], W2=zinb_all@W[,2]) %>% ggplot(aes(W1, W2)) + geom_point(aes(color=gata3), size=3) + scale_colour_gradient(low="blue", high="green") + theme_classic()
```

Interestingly, when using all the genes, things still work. 

## ZIFA (top 1000 most variable genes)

### Full algorithm

```{r zifa}
zifa_res <- read.csv("zifa_th2_full.csv", header=FALSE)

data.frame(Z1=zifa_res[,1], Z2=zifa_res[,2]) %>% ggplot(aes(Z1, Z2)) + geom_point(aes(color=gata3), size=3) + scale_colour_gradient(low="blue", high="green") + theme_classic()
```

### Block algorithm

```{r zifa_block}
zifa_res <- read.csv("zifa_th2.csv", header=FALSE)

data.frame(Z1=zifa_res[,1], Z2=zifa_res[,2]) %>% ggplot(aes(Z1, Z2)) + geom_point(aes(color=gata3), size=3) + scale_colour_gradient(low="blue", high="green") + theme_classic()
```
